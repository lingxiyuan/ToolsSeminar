{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Assignment --- Least Square Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encapsulate codes of gradient method to a least square regression into a class `Trainer`. Background is explained in `main.tex`.\n",
    "\n",
    "*Use `Run All` to generate data and find the standard output.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, training related functions `loss_func` and `train_func` are provided. Encapsulate these two function into a class `Trainer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1000\n",
    "a_true, b_true = 4., 5.\n",
    "a_0, b_0 = 0., 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=0\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = numpy.linspace(0., 10., n)\n",
    "y = a_true + b_true * x + numpy.random.randn(n)\n",
    "\n",
    "A = numpy.vstack((x, numpy.ones(n)))\n",
    "eta = 1. / numpy.linalg.norm(A.dot(A.transpose()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = [x, y, a_0, b_0, a_true, b_true, eta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x[:5])\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(x, y, a_t, b_t):\n",
    "    error = a_t + b_t * x - y\n",
    "    return 1. / 2. * numpy.sum(error**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(x, y, a_t, b_t, eta):\n",
    "    n = x.shape[0]\n",
    "    grad_a = numpy.ones(n).dot(a_t + b_t * x - y)\n",
    "    grad_b = x.dot(a_t + b_t * x - y)\n",
    "\n",
    "    a_tp1 = a_t - eta * grad_a\n",
    "    b_tp1 = b_t - eta * grad_b\n",
    "\n",
    "    return [a_tp1, b_tp1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip this part for your first reading. The key is used to generate standard output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyTrainer:\n",
    "    def __init__(self, config, loss_func, train_func):\n",
    "        self.x, self.y, self.a, self.b, self.a_true, self.b_true, self.eta = config\n",
    "        self.loss_func = loss_func\n",
    "        self.train_func = train_func\n",
    "        self.loss = float(\"inf\")\n",
    "        self.iter_ctr = 0\n",
    "\n",
    "    def one_iteration(self):\n",
    "        self.loss = self.loss_func(self.x, self.y, self.a, self.b)\n",
    "        print(\"#Iteration: {0}, loss: {1:.5f}\".format(self.iter_ctr, self.loss))\n",
    "        self.a, self.b = self.train_func(self.x, self.y, self.a, self.b, self.eta)\n",
    "        self.iter_ctr += 1\n",
    "\n",
    "    def go(self, n=1000):\n",
    "        for i in range(n):\n",
    "            self.one_iteration()\n",
    "\n",
    "    def result(self):\n",
    "        print(\"Final #iteration: {0}, loss: {1:.5f}\".format(self.iter_ctr, self.loss))\n",
    "        print(\"Result: a = {0:.5f}, b = {1:.5f}\".format(self.a, self.b))\n",
    "        print(\"Groundtruth:  a = {0:.5f}, b = {1:.5f}\".format(self.a_true, self.b_true))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = KeyTrainer(config, loss_func, train_func)\n",
    "\n",
    "trainer.go()\n",
    "\n",
    "trainer.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer should provide a class `Trainer`, which have a method `go(n=1000)` for training and printing intermediate results, where `n` specifies the number of iterations, and `result()` for printing final results. Try to achieve the standard output shown in the last section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(config, loss_func, train_func)\n",
    "\n",
    "trainer.go()\n",
    "\n",
    "trainer.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
